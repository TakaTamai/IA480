{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c45825e-0783-473b-adac-45bd7953b97e",
   "metadata": {},
   "source": [
    "# Exploring Twitter Data with Vector Databases and RAG Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c716f-6b4c-46e9-b6ad-10efc429fb22",
   "metadata": {},
   "source": [
    "This tutorial introduces the creation of a vector database and the use of a retrieval-augmented generation (RAG) system to explore Twitter data interactively. \n",
    "\n",
    "Please check [LBSocial](www.lbsocial.net)  on how to collect Twitter data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00579d-601d-4cd2-883e-8716fa956f6d",
   "metadata": {},
   "source": [
    "## Set up a Database and API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f19853-7955-4634-b649-fb870e6cbde6",
   "metadata": {},
   "source": [
    "Create a [MongoDB](www.mongodb.com) cluster and store the connection string in a safe place, such as AWS Secrets Manager. \n",
    "- key name: `connection_string`\n",
    "- key value: <`the connection string`>, you need to type the password\n",
    "- secret name: `mongodb`\n",
    "\n",
    "\n",
    "You also need to purchase and your [oepnai](https://openai.com/) api key in AWS Secrets Manager:\n",
    "- key name: `api_key`\n",
    "- key value: <`your openai api key`>\n",
    "- secret name: `openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741094a9-2341-428c-8890-6d25a7b5a57f",
   "metadata": {},
   "source": [
    "## Install Python Libraries\n",
    "\n",
    "- pymongo: manage the MongoDB database\n",
    "- openai: create embeddings and resonpses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0541cd55-a63a-4ea7-b109-64e638f68058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d81b42-f298-4dc9-a774-323ce4a7abd9",
   "metadata": {},
   "source": [
    "## Secrets Manager Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193ba904-b9ee-4079-87bf-7b9e079afddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f82551-7cae-45a8-901f-ded99fcb1c5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Python Libraries and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a90eb91-dbed-45c8-954f-ec6a59066975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "mongodb_connect = get_secret('mongodb')['connection_string']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f4198-edb0-4004-9ccb-c4f5cc083f33",
   "metadata": {},
   "source": [
    "## Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c730e7-cd46-4137-819a-c0de76c2f0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mongo_client = MongoClient(mongodb_connect)\n",
    "db = mongo_client.demo # use or create a database named demo\n",
    "tweet_collection = db.tweet_collection #use or create a collection named tweet_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19a687-2bd7-4650-a4bc-c2f22b29b314",
   "metadata": {},
   "source": [
    "## Utility Funcitons\n",
    "\n",
    "- the `clean_tweet` function removes URLs in tweets\n",
    "- the `get_embedding` function use openai to create tweet embeddings\n",
    "- the `vector_search` function return relevent tweets based on a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bdc6aa-c9b9-4fa8-b076-e901e10ef7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(url_pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a14ad6e-f65b-4214-a935-acc6162116cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model= 'text-embedding-3-small'\n",
    "\n",
    "def get_embedding(text):\n",
    "\n",
    "    try:\n",
    "        embedding = client.embeddings.create(input=text, model=embedding_model).data[0].embedding\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4584482b-2cc8-47e4-8d42-d303975b4353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vector_search(query):\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "    # Define the vector search pipeline\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"tweet_vector\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"tweet.embedding\",\n",
    "                \"numCandidates\": 1000,  # Number of candidate matches to consider\n",
    "                \"limit\": 10  # Return top 10 matches\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,  # Exclude the _id field\n",
    "                \"tweet.text\": 1 # return tweet text\n",
    "\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = tweet_collection.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb5866-c09b-4779-b139-80d041a693f8",
   "metadata": {},
   "source": [
    "## Tweets Embedding \n",
    "\n",
    "For more about text embeddings please read [Introducing text and code embeddings](https://openai.com/index/introducing-text-and-code-embeddings/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f08f57-06f8-4e9c-9388-75da5d0ea6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d880cd80934a4f7fb801000ebaa5fa94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tweets = tweet_collection.find()\n",
    "\n",
    "for tweet in tqdm(list(tweets)):\n",
    "    try:\n",
    "        tweet_embedding = get_embedding(clean_tweet(tweet['tweet']['text']))\n",
    "    #     print(tweet_embedding)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "            {'tweet.id':tweet['tweet']['id']},\n",
    "            {\"$set\":{'tweet.embedding':tweet_embedding}}\n",
    "        )\n",
    "    except:\n",
    "        print(f\"\"\"error in embedding tweet {tweet['tweet']['id']}\"\"\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b8a55-60c7-4c9f-a64f-3861421e281c",
   "metadata": {},
   "source": [
    "## Create a Vector Index\n",
    "\n",
    "For more about the MognoDB Vector database, please read [What are Vector Databases?](https://www.mongodb.com/resources/basics/databases/vector-databases)\n",
    "This code creates a vector index following the [MongoDB official document](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#std-label-avs-types-vector-search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ec0671-54a7-4c21-bb49-8019bc7437c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New search index named tweet_vector is building.\n",
      "Polling to check if the index is ready. This may take up to a minute.\n",
      "tweet_vector is ready for querying.\n"
     ]
    }
   ],
   "source": [
    "# Create your index model, then create the search index\n",
    "\n",
    "from pymongo.operations import SearchIndexModel\n",
    "import time\n",
    "\n",
    "search_index_model = SearchIndexModel(\n",
    "  definition={\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"tweet.embedding\",\n",
    "      \"numDimensions\": 1536,\n",
    "      \"similarity\": \"cosine\"\n",
    "    }\n",
    "  ]\n",
    "},\n",
    "  name=\"tweet_vector\",\n",
    "  type=\"vectorSearch\"\n",
    "\n",
    ")\n",
    "result = tweet_collection.create_search_index(model=search_index_model)\n",
    "print(\"New search index named \" + result + \" is building.\")\n",
    "# Wait for initial sync to complete\n",
    "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
    "predicate=None\n",
    "\n",
    "if predicate is None:\n",
    "  predicate = lambda index: index.get(\"queryable\") is True\n",
    "\n",
    "while True:\n",
    "  indices = list(tweet_collection.list_search_indexes(result))\n",
    "  if len(indices) and predicate(indices[0]):\n",
    "\n",
    "    break\n",
    "  time.sleep(5)\n",
    "\n",
    "print(result + \" is ready for querying.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54c039e-9f47-4a34-8dfe-5c13f8cc2b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Election ploy ü§∑üèæ‚Äç‚ôÇÔ∏è https://t.co/60VhB47cXA\n",
      "RT @Indian_Analyzer: Rajiv Kumar, Election Commissioner:\n",
      "\"6 days before polling, New Battery is inserted into the EVMs. Even Battery has to‚Ä¶\n",
      "Couldn't you quote your idol Mao, or would you fumble the election? https://t.co/W6fuRj0b2k https://t.co/UBzwK0mMUq\n",
      "Unlocking wealth through calculated risk and strategic patience is a marathon not a sprint\n",
      "High-speed trading is like sprinting towards a finish line, but what lies ahead is a marathon of smart contracts and complex strategies\n",
      "üíô The Marathon Continue üèÅ SIP King üïäÔ∏è https://t.co/agPgi8wtm2\n",
      "üîçüîí Transparency Meets Security\n",
      "\n",
      "üìä This Cybersecurity Awareness Month, we‚Äôre proud to highlight Enhanced Voting‚Äôs election results platform, offering 100% uptime with real-time updates. Our platform allows voters to engage with interactive maps and graphs, ensuring transparency‚Ä¶ https://t.co/v14acBW6KL https://t.co/N1dqDL78y1\n",
      "RT @wiley_inc: @EdanClay Let me remind you\n",
      "\n",
      "1) Polls are ephemeral \n",
      "2) Polls are numerous\n",
      "3) Polls have no predictive value\n",
      "4) Polls vary,‚Ä¶\n",
      "Investing wisely is like training for a marathon, you need to pace yourself and stay focused on your long-term goals\n",
      "Maximizing returns on a portfolio is like training for a marathon, you need to pace yourself and make strategic moves at the right time\n"
     ]
    }
   ],
   "source": [
    "user_query = 'AI'\n",
    "\n",
    "for tweet in vector_search(user_query):\n",
    "    print(tweet['tweet']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe41db-4fa6-4269-b32c-1acd5d8e0756",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG) \n",
    "\n",
    "For more about RAG, please read [Retrieval-Augmented Generation (RAG) with Atlas Vector Search](https://www.mongodb.com/docs/atlas/atlas-vector-search/rag/#std-label-avs-rag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700df598-edc6-4df5-a451-af64200e60f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "delimiter = '###'\n",
    "chat_model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "chat_history = [{\"role\": \"system\", \"content\": \"\"\"you are a chabot answer user questions based on the returned tweets\"\"\"}]\n",
    "\n",
    "def chatbot(prompt):\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    tweets = vector_search(prompt)\n",
    "    chat_history.append({\"role\": \"system\", \"content\": f\"here the returned tweets delimitered by {delimiter}{tweets}{delimiter}\"})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_model,  # Use the model you prefer\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b76db5ca-abb0-4c64-a85c-0fabb74f55ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  tariffs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: The returned tweets do not contain any information directly related to tariffs. They cover topics such as limited-time campaigns, prediction markets related to Trump's election chances, trading strategies, election poll results, and bureaucratic challenges faced by Trump‚Äôs cabinet. If you have specific questions about tariffs or need information on a different topic, feel free to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  constitution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: The returned tweets focus on topics related to elections, such as legality around voter registration, claims about election fairness, court rulings on election result certifications, and debates about election legitimacy. However, none of the tweets specifically mention the U.S. Constitution or constitutional topics. If you have specific questions about the Constitution or if you're looking for particular information, please let me know!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  virginia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: The tweets mention Virginia in the context of election integrity efforts and voter roll cleanup. Specifically, they discuss Governor Glenn Youngkin and his initiatives for maintaining election integrity in Virginia, as well as criticisms related to election-related actions by the Department of Justice. Additionally, there are mentions of Donald Trump referencing these actions in Virginia as part of broader discussions about election interference. If you have more specific questions or need further information about Virginia, feel free to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  democrats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: The tweets mention Democrats in various contexts related to elections and politics. Key themes include:\n",
      "\n",
      "1. Criticism of Democrats' stance on voter ID laws and election integrity measures, with some suggesting that Democrats are planning to \"steal\" upcoming elections.\n",
      "2. Encouragement among Democrats to unify and be vocal as the 2024 election approaches, highlighting a need for active participation.\n",
      "3. Concerns about the influence of dark money in politics and its impact as Election Day 2024 approaches.\n",
      "4. Discussion on Kamala Harris's platform, with some tweets sarcastically suggesting inadequacies or commenting on Democrats' overall approach to election integrity.\n",
      "5. Commentary suggesting that Democrats and media need to raise awareness about certain political happenings.\n",
      "\n",
      "These discussions reflect a broader dialogue on election integrity, voter participation, and the political strategies of Democrats leading up to upcoming elections. If you have more specific questions or need detailed insights on a particular aspect, feel free to ask!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot: Goodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    reply = chatbot(user_input)\n",
    "    print(f\"Chatbot: {reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285852d-2eff-4a06-9865-1e9b0c70da7d",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- *‚ÄúIntroducing Text and Code Embeddings.‚Äù* n.d. OpenAI. Accessed October 31, 2024. https://openai.com/index/introducing-text-and-code-embeddings/.\n",
    "- *‚ÄúWhat Are Vector Databases?‚Äù* n.d. MongoDB. Accessed October 31, 2024. https://www.mongodb.com/resources/basics/databases/vector-databases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
